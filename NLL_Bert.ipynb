{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import random\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def log10(x):\n",
    "  numerator = K.log(x)\n",
    "  denominator = K.log(K.constant(10, dtype=numerator.dtype))\n",
    "  return numerator / denominator\n",
    "\n",
    "def gaussian_nll(ytrue, ypreds):\n",
    "    \"\"\"Keras implmementation of multivariate Gaussian negative loglikelihood loss function. \n",
    "    This implementation implies diagonal covariance matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ytrue: tf.tensor of shape [n_samples, n_dims]\n",
    "        ground truth values\n",
    "    ypreds: tf.tensor of shape [n_samples, n_dims*2]\n",
    "        predicted mu and logsigma values (e.g. by your neural network)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    neg_log_likelihood: float\n",
    "        negative loglikelihood averaged over samples\n",
    "        \n",
    "    This loss can then be used as a target loss for any keras model, e.g.:\n",
    "        model.compile(loss=gaussian_nll, optimizer='Adam') \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_dims = int(int(ypreds.shape[1])/2)\n",
    "    mu = ypreds[:, 0:n_dims]\n",
    "    logsigma = ypreds[:, n_dims:]\n",
    "    \n",
    "    mse = 0.5*K.sum(K.square(ytrue-mu)/(logsigma),axis=1)\n",
    "    sigma_trace = 0.5*K.sum(log10(logsigma), axis=1)\n",
    "    log2pi = 0.5*n_dims*np.log(2*np.pi)\n",
    "    \n",
    "    log_likelihood = mse+sigma_trace+log2pi\n",
    "\n",
    "    return K.mean(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/data/task-1/test_eval.csv\"\n",
    "\n",
    "test_eval=pd.read_csv(test_eval_data)\n",
    "test_eval_label1=test_eval.meanGrade\n",
    "test_eval_label2=test_eval.grades\n",
    "#get orignial news\n",
    "test_eval_news=test_eval.original\n",
    "test_eval_funny_word=test_eval.edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "tt=nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "punctuation = '!,;:?\"\\'.\\'/<>'\n",
    "def removePunctuation(text):\n",
    "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
    "    return text.strip()\n",
    "\n",
    "#catch the changed word\n",
    "def find_tag(news):\n",
    "    p = re.compile(r'[<](.*?)/[>]', re.S)\n",
    "    return re.findall(p, news)\n",
    "\n",
    "def preprocess_news(sentence,funny_word):\n",
    "    final=[]\n",
    "    num=0\n",
    "    bad_sign=[\"’\",\"‘\",\"-\"]\n",
    "    \n",
    "    for event in sentence:\n",
    "        lines=[]       \n",
    "        event=str(event)\n",
    "        changed_word=find_tag(event)   \n",
    "        event=removePunctuation(event)\n",
    "        event=tt.tokenize(event)\n",
    "        #tokenize and remove Punctuation\n",
    "        \n",
    "        for i in event:\n",
    "            if i not in bad_sign:\n",
    "                \n",
    "                if i in changed_word:\n",
    "                    #add the funny behind the changed word\n",
    "                    #lines.append(i)\n",
    "                    lines.append(funny_word[num])\n",
    "                else:\n",
    "                    lines.append(i)\n",
    "                    \n",
    "        lines=' '.join(lines)\n",
    "        lines='[CLS]'+' '+lines+' '+'[SEP]'\n",
    "        final.append(lines)\n",
    "        num+=1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean and varience for each headline\n",
    "test_eval_label=[]\n",
    "test_eval_label3=[]\n",
    "for i in range(0,len(test_eval_label1)):\n",
    "    label1=test_eval_label1[i]\n",
    "    label2=str(test_eval_label2[i])\n",
    "    mean=label1\n",
    "    \n",
    "    def get_grade(label):\n",
    "        grade=[]\n",
    "        for i in label:\n",
    "            grade.append(int(i))\n",
    "        return grade\n",
    "    \n",
    "    grade=get_grade(label2)\n",
    "    \n",
    "    #get varience \n",
    "    def get_var(grade,mean):\n",
    "        Var=0\n",
    "        for i in grade:\n",
    "            var=np.square(grade-mean)\n",
    "            Var+=var\n",
    "        return np.mean(Var)\n",
    "    \n",
    "    var=np.sqrt(get_var(grade,mean))\n",
    "    test_eval_label3.append(float(var))\n",
    "    test_eval_label.append([mean,var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_news=preprocess_news(test_eval_news,test_eval_funny_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] The Latest Election tally shows Cars turning right [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2',token_ids_1=None)\n",
    "inputs_train = tokenizer(test_eval_news,padding=True,return_tensors=\"pt\")\n",
    "inputs_train=np.array(inputs_train['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 37)]              0         \n",
      "_________________________________________________________________\n",
      "tf_albert_model_1 (TFAlbertM TFBaseModelOutputWithPool 11683584  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 11,684,353\n",
      "Trainable params: 11,684,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer=tf.keras.Input(shape=(37,),dtype='int64')\n",
    "bert=TFAlbertModel.from_pretrained('albert-base-v2', return_dict=True)(input_layer)\n",
    "layer1=bert[1]\n",
    "regression=tf.keras.layers.Dense(1)(layer1)\n",
    "#result=Lambda(negative_binomial_layer)(regression)\n",
    "model=tf.keras.Model(inputs=input_layer,outputs=regression)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 37) for input Tensor(\"input_2:0\", shape=(None, 37), dtype=int64), but it was called on an input with incompatible shape (1, 36).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 37) for input Tensor(\"input_2:0\", shape=(None, 37), dtype=int64), but it was called on an input with incompatible shape (1, 36).\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4881 - mean_squared_error: 0.4881WARNING:tensorflow:Model was constructed with shape (None, 37) for input Tensor(\"input_2:0\", shape=(None, 37), dtype=int64), but it was called on an input with incompatible shape (1, 36).\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4881 - mean_squared_error: 0.4881 - val_loss: 0.4906 - val_mean_squared_error: 0.4906\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 10s 968ms/step - loss: 0.5360 - mean_squared_error: 0.5360 - val_loss: 0.5694 - val_mean_squared_error: 0.5694\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.5294 - mean_squared_error: 0.5294 - val_loss: 0.5475 - val_mean_squared_error: 0.5475\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5014 - mean_squared_error: 0.5014 - val_loss: 0.5398 - val_mean_squared_error: 0.5398\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5067 - mean_squared_error: 0.5067 - val_loss: 0.5453 - val_mean_squared_error: 0.5453\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4991 - mean_squared_error: 0.4991 - val_loss: 0.5200 - val_mean_squared_error: 0.5200\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4941 - mean_squared_error: 0.4941 - val_loss: 0.5384 - val_mean_squared_error: 0.5384\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4978 - mean_squared_error: 0.4978 - val_loss: 0.5420 - val_mean_squared_error: 0.5420\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5021 - mean_squared_error: 0.5021 - val_loss: 0.5281 - val_mean_squared_error: 0.5281\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4880 - mean_squared_error: 0.4880 - val_loss: 0.5151 - val_mean_squared_error: 0.5151\n"
     ]
    }
   ],
   "source": [
    "opt=tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "metric = tf.keras.metrics.MeanSquaredError()\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(),metrics=[metric])\n",
    "model_fit = model.fit(inputs_train, np.array(test_eval_label3),\n",
    "                      batch_size=1, epochs=10,\n",
    "                      validation_data=(inputs_train[:100],np.array(test_eval_label3[:100]))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob(model, x, batch_size=2048):\n",
    "    \"\"\"Make predictions given model and 2d data\n",
    "    \"\"\"\n",
    "\n",
    "    ypred = model.predict(x, batch_size=batch_size, verbose=1)\n",
    "    n_outs = int(ypred.shape[1] / 2)\n",
    "    mean = ypred[:, 0:n_outs]\n",
    "    sigma = np.exp(ypred[:, n_outs:])\n",
    "\n",
    "    return mean, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test,result):\n",
    "    pre=model.predict(test)\n",
    "    pres=[]\n",
    "    for i in pre:\n",
    "        #a=float(i)*3\n",
    "        pres.append(i)\n",
    "    print(pres)\n",
    "    rmse = np.sqrt(np.mean((np.array(result) - np.array(pres))**2))\n",
    "\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 37) for input Tensor(\"input_2:0\", shape=(None, 37), dtype=int64), but it was called on an input with incompatible shape (None, 36).\n",
      "[array([1.259876], dtype=float32), array([1.2499784], dtype=float32), array([1.2339311], dtype=float32), array([1.2576215], dtype=float32), array([1.2453129], dtype=float32), array([1.2411587], dtype=float32), array([1.2606369], dtype=float32), array([1.2428229], dtype=float32), array([1.2592647], dtype=float32), array([1.2514399], dtype=float32), array([1.2540429], dtype=float32), array([1.2495706], dtype=float32), array([1.2440271], dtype=float32), array([1.2461654], dtype=float32), array([1.2555704], dtype=float32), array([1.2469335], dtype=float32), array([1.253432], dtype=float32), array([1.2503792], dtype=float32), array([1.245656], dtype=float32), array([1.2538016], dtype=float32), array([1.2523233], dtype=float32), array([1.2451394], dtype=float32), array([1.255726], dtype=float32), array([1.2542164], dtype=float32), array([1.2459944], dtype=float32), array([1.2579632], dtype=float32), array([1.2486812], dtype=float32), array([1.2513736], dtype=float32), array([1.2455356], dtype=float32), array([1.2501967], dtype=float32), array([1.2566247], dtype=float32), array([1.2455611], dtype=float32), array([1.255373], dtype=float32), array([1.256357], dtype=float32), array([1.2453892], dtype=float32), array([1.2577863], dtype=float32), array([1.2554865], dtype=float32), array([1.2484094], dtype=float32), array([1.252801], dtype=float32), array([1.2424967], dtype=float32), array([1.2487215], dtype=float32), array([1.2477677], dtype=float32), array([1.2472453], dtype=float32), array([1.2562373], dtype=float32), array([1.2522187], dtype=float32), array([1.2549667], dtype=float32), array([1.2491438], dtype=float32), array([1.240261], dtype=float32), array([1.2501311], dtype=float32), array([1.24319], dtype=float32), array([1.2560728], dtype=float32), array([1.2458165], dtype=float32), array([1.2543225], dtype=float32), array([1.2558106], dtype=float32), array([1.2474713], dtype=float32), array([1.2430713], dtype=float32), array([1.244704], dtype=float32), array([1.2512131], dtype=float32), array([1.2504802], dtype=float32), array([1.2450345], dtype=float32), array([1.2408378], dtype=float32), array([1.2529141], dtype=float32), array([1.2462568], dtype=float32), array([1.2492322], dtype=float32), array([1.2545147], dtype=float32), array([1.2458575], dtype=float32), array([1.254969], dtype=float32), array([1.2521753], dtype=float32), array([1.2538049], dtype=float32), array([1.2455842], dtype=float32), array([1.25421], dtype=float32), array([1.2516181], dtype=float32), array([1.2578529], dtype=float32), array([1.2458342], dtype=float32), array([1.248847], dtype=float32), array([1.2487719], dtype=float32), array([1.2513554], dtype=float32), array([1.2392766], dtype=float32), array([1.2528132], dtype=float32), array([1.2556561], dtype=float32), array([1.2497641], dtype=float32), array([1.2588575], dtype=float32), array([1.2498031], dtype=float32), array([1.2407467], dtype=float32), array([1.2512455], dtype=float32), array([1.2573391], dtype=float32), array([1.2560155], dtype=float32), array([1.2473824], dtype=float32), array([1.2485318], dtype=float32), array([1.2469265], dtype=float32), array([1.2449596], dtype=float32), array([1.2516378], dtype=float32), array([1.2554511], dtype=float32), array([1.2447748], dtype=float32), array([1.2582927], dtype=float32), array([1.2488194], dtype=float32), array([1.2585697], dtype=float32), array([1.2487669], dtype=float32), array([1.2541754], dtype=float32), array([1.2534153], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7194494330720006"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(inputs_train[:100],test_eval_label3[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2, 0.4, 1. , 1.6, 0.4, 0.6, 1.6, 1.2, 1. , 0.4, 1.6, 0.6, 0.2,\n",
       "       0.2, 1.8, 0.2, 0.4, 1.4, 0. , 2.2, 1. , 0.8, 1.2, 0.6, 2.2, 0.8,\n",
       "       0.6, 1. , 0.4, 0.6, 0.2, 0.8, 1.6, 1.2, 2. , 1. , 0.6, 0. , 0.4,\n",
       "       0.8, 0.6, 0.8, 0.8, 0.6, 1. , 1. , 1.2, 0.8, 2. , 1. , 1.6, 1.6,\n",
       "       1.2, 0.2, 1. , 0.4, 0.4, 0. , 0.8, 0.6, 1. , 1. , 1.8, 1.2, 0.2,\n",
       "       0.6, 0.8, 0. , 1.4, 0.6, 0.6, 0.6, 1.2, 1.2, 1. , 0. , 1.6, 1.4,\n",
       "       1.4, 0.2, 1.2, 0.4, 1.2, 0.4, 1. , 0.4, 0.2, 0. , 1.2, 0.4, 0.6,\n",
       "       0.4, 2. , 0.6, 1.9, 1.2, 0.8, 1. , 1.8, 1.8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_eval_label1[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
