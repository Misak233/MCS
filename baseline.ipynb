{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/train.csv\"\n",
    "test_data=\"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/dev.csv\"\n",
    "\n",
    "#get data with ascending sort by score\n",
    "train=pd.read_csv(train_data)\n",
    "column=train.columns.values\n",
    "test=train[9100:]\n",
    "train=train[:9100]\n",
    "test = test.sort_values(column[4],ascending=False)\n",
    "test_label=test.meanGrade\n",
    "\n",
    "#get label\n",
    "train_label=train.meanGrade\n",
    "train_label=train_label\n",
    "\n",
    "#get orignial news\n",
    "train_news=train.original\n",
    "train_funny_word=train.edit\n",
    "test_news=test.original\n",
    "test_funny_word=test.edit\n",
    "a=[]\n",
    "for i in test_funny_word:\n",
    "    a.append(i)\n",
    "test_funny_word=a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is ‘ hunting down its citizens who joined <Isis/> ’ without trial in Iraq\n"
     ]
    }
   ],
   "source": [
    "#extract edited word from news\n",
    "def find_tag(news):\n",
    "    p = re.compile(r'[<](.*?)/[>]', re.S)\n",
    "    return re.findall(p, news)\n",
    "print(train_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do preprocess\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "tt=nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_news(sentence,funny_word):\n",
    "    final=[]\n",
    "    num=0\n",
    "    for event in sentence:\n",
    "        BOW={}\n",
    "        ori=event\n",
    "        \n",
    "        #tokenize and remove Punctuation\n",
    "        event=removePunctuation(event)\n",
    "        event=tt.tokenize(event)\n",
    "        for words in event:\n",
    "            words=lemmatizer.lemmatize(words)\n",
    "            if words not in stopwords:\n",
    "                \n",
    "                #generate Bag of words\n",
    "                BOW[words.lower()]=BOW.get(words,0)+1\n",
    "        \n",
    "        #give more weight for funny word\n",
    "        BOW[funny_word[num].lower()]=BOW.get(funny_word[num],0)+10\n",
    "        final.append(BOW)\n",
    "        num+=1\n",
    "    return final\n",
    "\n",
    "punctuation = '!,;:?\"\\'.\\'/<>'\n",
    "def removePunctuation(text):\n",
    "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
    "    return text.strip()\n",
    "\n",
    "train_news=preprocess_news(train_news,train_funny_word)\n",
    "test_news=preprocess_news(test_news,test_funny_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100\n",
      "552\n",
      "9100\n",
      "552\n",
      "{'france': 1, '‘': 1, 'hunting': 1, 'citizen': 1, 'joined': 1, 'isis': 1, '’': 1, 'without': 1, 'trial': 1, 'iraq': 1, 'twins': 10}\n"
     ]
    }
   ],
   "source": [
    "print(len(train_news))\n",
    "print(len(test_news))\n",
    "print(len(train_label))\n",
    "print(len(test_label))\n",
    "print(train_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552, 10191)\n",
      "(9100,)\n",
      "(9100, 10191)\n"
     ]
    }
   ],
   "source": [
    "#transform to vector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer=DictVectorizer()\n",
    "transformer=TfidfTransformer(smooth_idf=False,norm=None)\n",
    "train_matrix=vectorizer.fit_transform(train_news)\n",
    "#use TF_IDF\n",
    "train_matrix=transformer.fit_transform(train_matrix)\n",
    "\n",
    "#transform test\n",
    "test_matrix=vectorizer.transform(test_news)\n",
    "test_matrix=transformer.transform(test_matrix)\n",
    "print(test_matrix.shape)\n",
    "print(train_label.shape)\n",
    "print(train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do prediction and evaluation matrix for later works\n",
    "def prediction(model):\n",
    "    #best=model.fit(train_matrix,train_label)\n",
    "    pre=model.predict(test_matrix)\n",
    "    rmse = np.sqrt(np.mean((test_label - pre)**2))\n",
    "    psr=stats.pearsonr(np.array(pre),np.array(test_label))\n",
    "    print(\"The person correlation coefficient is:\")\n",
    "    print(psr)\n",
    "    print(\"The result of RMSE in the whole test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:100])\n",
    "    rmse = np.sqrt(np.mean((test_label[:100] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 10% test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:200])\n",
    "    rmse = np.sqrt(np.mean((test_label[:200] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 20% test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:300])\n",
    "    rmse = np.sqrt(np.mean((test_label[:300] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 30% test data is:\")\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'alpha': 0.01} with R2——score of 0.0798\n",
      "The person correlation coefficient is:\n",
      "(0.334611925031881, 6.5954222220342e-16)\n",
      "The result of RMSE in the whole test data is:\n",
      "0.5330091503585478\n",
      "The result of RMSE in the BEST 10% test data is:\n",
      "0.8391077177188763\n",
      "The result of RMSE in the BEST 20% test data is:\n",
      "0.6467736174689563\n",
      "The result of RMSE in the BEST 30% test data is:\n",
      "0.5334505744550625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit,GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import make_scorer,mean_squared_error,r2_score\n",
    "\n",
    "#use MSE as scorer\n",
    "#scorer=make_scorer(mean_squared_error)\n",
    "scorer=make_scorer(r2_score)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.1, random_state=0)\n",
    "\n",
    "#LASSO Method (alpha from 0.1 to 100)\n",
    "a=np.logspace(-2,4,10)\n",
    "lasso=linear_model.Lasso(fit_intercept=True)\n",
    "grid=GridSearchCV(lasso,param_grid={'alpha':a},cv=cv,scoring=scorer)\n",
    "grid.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2——score of {0.best_score_:.3g}\".format(grid))\n",
    "best=grid.best_estimator_ \n",
    "prediction(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/data/task-1/test_eval.csv\"\n",
    "\n",
    "test_eval=pd.read_csv(test_eval_data)\n",
    "test_eval_label=test_eval.meanGrade\n",
    "\n",
    "#get orignial news\n",
    "test_eval_news=test_eval.original\n",
    "test_eval_funny_word=test_eval.edit\n",
    "\n",
    "test_eval_news=preprocess_news(test_eval_news,test_eval_funny_word)\n",
    "test_eval_matrix=vectorizer.transform(test_eval_news)\n",
    "test_eval_matrix=transformer.transform(test_eval_matrix)\n",
    "\n",
    "pre=grid.predict(test_eval_matrix)\n",
    "rmse = np.sqrt(np.mean((test_eval_label - pre)**2))\n",
    "\n",
    "import pandas as pd\n",
    "id=test_eval.id\n",
    "dataframe = pd.DataFrame({'id':id,'pred':pre})\n",
    "dataframe.to_csv(\"task-1-output.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'alpha': 16681.005372000593} with R2-score of 0.0921\n",
      "The person correlation coefficient is:\n",
      "(0.334558900664955, 6.669315156841847e-16)\n",
      "The result of RMSE in the whole test data is:\n",
      "0.5332356662450543\n",
      "The result of RMSE in the BEST 10% test data is:\n",
      "0.8166910431997259\n",
      "The result of RMSE in the BEST 20% test data is:\n",
      "0.6333492806158451\n",
      "The result of RMSE in the BEST 30% test data is:\n",
      "0.5262552755566311\n"
     ]
    }
   ],
   "source": [
    "#ridge method \n",
    "ridge=linear_model.Ridge(solver='sparse_cg')\n",
    "a=np.logspace(-2,5,10)\n",
    "grid2=GridSearchCV(ridge,param_grid={'alpha':a},cv=cv,scoring=scorer)\n",
    "grid2.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid2))\n",
    "prediction(grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#elasticnet method\n",
    "#alpha and ratio for L1\n",
    "a=np.linspace(0.01,5,10)\n",
    "b=np.linspace(0,1,5)\n",
    "elastic=linear_model.ElasticNet()\n",
    "\n",
    "grid3=GridSearchCV(elastic,param_grid={'alpha':a,'l1_ratio':b},cv=cv,scoring=make_scorer(mean_squared_error))\n",
    "grid3.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid3))\n",
    "prediction(grid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from sklearn.svm import SVR\n",
    "c_range=np.logspace(-2,5,10)\n",
    "gamma=np.logspace(-5,1,10)\n",
    "degree=[0,1,2,3,4]\n",
    "svr=SVR(kernel='poly')\n",
    "\n",
    "grid4=GridSearchCV(svr,param_grid={'epsilon':epsilon,'C':c_range,'degree':degree},cv=cv,scoring=scorer)\n",
    "grid4.fit(train_matrix,train_label)\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid4))\n",
    "prediction(grid4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
