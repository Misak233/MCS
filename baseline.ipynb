{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/train.csv\"\n",
    "train_data_2=\"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/data/task-1/train_funlines.csv\"\n",
    "test_data=\"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/data/task-1/dev.csv\"\n",
    "test_eval_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/data/task-1/test_eval.csv\"\n",
    "\n",
    "test_eval=pd.read_csv(test_eval_data)\n",
    "test_eval_label=test_eval.meanGrade\n",
    "\n",
    "#get orignial news\n",
    "test_eval_news=test_eval.original\n",
    "test_eval_funny_word=test_eval.edit\n",
    "#get data with ascending sort by score\n",
    "train1=pd.read_csv(train_data)\n",
    "train2=pd.read_csv(train_data_2)\n",
    "test=pd.read_csv(test_data)\n",
    "\n",
    "#get label\n",
    "train_label=list(train1.meanGrade)+list(train2.meanGrade)\n",
    "test_label=test.meanGrade\n",
    "\n",
    "#get orignial news\n",
    "train_news=list(train1.original)+list(train2.original)\n",
    "train_funny_word=list(train1.edit)+list(train2.edit)\n",
    "test_news=test.original\n",
    "test_funny_word=test.edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=list(train_news)+list(test_news)+list(test_eval_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is ‘ hunting down its citizens who joined <Isis/> ’ without trial in Iraq\n"
     ]
    }
   ],
   "source": [
    "#extract edited word from news\n",
    "def find_tag(news):\n",
    "    p = re.compile(r'[<](.*?)/[>]', re.S)\n",
    "    return re.findall(p, news)\n",
    "print(train_news[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do preprocess\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "tt=nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_news(sentence,funny_word):\n",
    "    final=[]\n",
    "    num=0\n",
    "    for event in sentence:\n",
    "        BOW={}\n",
    "        ori=event\n",
    "        \n",
    "        #tokenize and remove Punctuation\n",
    "        event=removePunctuation(event)\n",
    "        event=tt.tokenize(event)\n",
    "        for words in event:\n",
    "            words=lemmatizer.lemmatize(words)\n",
    "            if words not in stopwords:\n",
    "                \n",
    "                #generate Bag of words\n",
    "                BOW[words.lower()]=BOW.get(words,0)+1\n",
    "        \n",
    "        #give more weight for funny word\n",
    "        BOW[funny_word[num].lower()]=BOW.get(funny_word[num],0)+10\n",
    "        final.append(BOW)\n",
    "        num+=1\n",
    "    return final\n",
    "\n",
    "punctuation = '!,;:?\"\\'.\\'/<>'\n",
    "def removePunctuation(text):\n",
    "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news=preprocess_news(train_news,train_funny_word)\n",
    "test_news=preprocess_news(test_news,test_funny_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def convert_sentence(sentence):\n",
    "    return [\"<s>\"] + [w.lower() for w in sentence] + [\"</s>\"]\n",
    "\n",
    "def get_counts(sentences):\n",
    "    bigram_counts = defaultdict(Counter)\n",
    "    unigram_counts = Counter()\n",
    "    start_count = 0  # \"<s>\" counts: need these for bigram probs\n",
    "\n",
    "    # collect initial unigram statistics\n",
    "    for sentence in sentences:\n",
    "        sentence=removePunctuation(sentence)\n",
    "        sentence=tt.tokenize(sentence)\n",
    "        sentence = convert_sentence(sentence)\n",
    "        for word in sentence: # from 1, so we don't generate the <s> token\n",
    "            unigram_counts[word] += 1\n",
    "        start_count += 1\n",
    "\n",
    "    # collect bigram counts\n",
    "    for sentence in sentences:\n",
    "        sentence=removePunctuation(sentence)\n",
    "        sentence=tt.tokenize(sentence)\n",
    "        sentence = convert_sentence(sentence)\n",
    "        # generate a list of bigrams\n",
    "        bigram_list = zip(sentence[:-1], sentence[1:])\n",
    "        # iterate over bigrams\n",
    "        for bigram in bigram_list:\n",
    "            first, second = bigram\n",
    "            bigram_counts[first][second] += 1\n",
    "            \n",
    "    token_count = float(sum(unigram_counts.values()))\n",
    "    return unigram_counts, bigram_counts, start_count, token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts, bigram_counts, start_count, token_count=get_counts(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\"+\"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bigram(sentence,funny_word):\n",
    "    final=[]\n",
    "    num=0\n",
    "    for event in sentence:\n",
    "        BOW = defaultdict(Counter)\n",
    "        ori=event\n",
    "        \n",
    "        #tokenize and remove Punctuation\n",
    "        event=removePunctuation(event)\n",
    "        event=tt.tokenize(event)\n",
    "        event=convert_sentence(event)\n",
    "        for num in range(len(event)-1):\n",
    "                word1=event[num]\n",
    "                word2=event[num+1]\n",
    "                score=bigram_counts[word1][word2]/unigram_counts[word1]\n",
    "                #generate Bag of words\n",
    "                BOW[(word1,word2)]=score\n",
    "        \n",
    "        #give more weight for funny word\n",
    "        final.append(BOW)\n",
    "        num+=1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news=preprocess_bigram(train_news,train_funny_word)\n",
    "test_news=preprocess_bigram(test_news,test_funny_word)\n",
    "test_eval_news=preprocess_bigram(test_eval_news,test_eval_funny_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17900\n",
      "2419\n",
      "17900\n",
      "2419\n",
      "  (0, 73916)\t0.013756779143558282\n",
      "  (0, 73294)\t0.02032273313031601\n",
      "  (0, 71846)\t0.33816082685444426\n",
      "  (0, 70921)\t0.06700882744120325\n",
      "  (0, 65874)\t0.19002548748906983\n",
      "  (0, 35813)\t3.635228888685276\n",
      "  (0, 35304)\t0.2503567734409228\n",
      "  (0, 35174)\t0.12793049508229176\n",
      "  (0, 34827)\t0.37768611830496374\n",
      "  (0, 34485)\t1.7862453223963788\n",
      "  (0, 33211)\t0.05070463729431917\n",
      "  (0, 31756)\t3.2313145677202453\n",
      "  (0, 26782)\t0.33816082685444426\n",
      "  (0, 21729)\t0.2045635573318362\n",
      "  (0, 16025)\t1.5306226899727478\n",
      "  (0, 2822)\t0.013486641503341827\n",
      "  (1, 70661)\t0.21175482070468563\n",
      "  (1, 65984)\t1.5306226899727478\n",
      "  (1, 62261)\t0.062216247150370906\n",
      "  (1, 61011)\t0.5302754899175008\n",
      "  (1, 60063)\t0.31610685988567616\n",
      "  (1, 54088)\t0.13730935897874663\n",
      "  (1, 47913)\t0.31958056164266163\n",
      "  (1, 39987)\t2.2957795198486863\n",
      "  (1, 33513)\t0.018360663708552775\n",
      "  :\t:\n",
      "  (17898, 69456)\t0.7456879771662105\n",
      "  (17898, 58911)\t0.0019612131549752586\n",
      "  (17898, 54856)\t0.7136912123436567\n",
      "  (17898, 54401)\t0.6270459618287865\n",
      "  (17898, 53615)\t10.792555991828847\n",
      "  (17898, 49904)\t0.5139312377061356\n",
      "  (17898, 35737)\t0.11126346383328707\n",
      "  (17898, 30345)\t0.7559843214272978\n",
      "  (17898, 25791)\t0.019995647691125197\n",
      "  (17898, 11793)\t4.844150398607453\n",
      "  (17898, 3103)\t0.008807417999399577\n",
      "  (17899, 70806)\t0.1349069498978606\n",
      "  (17899, 70133)\t0.020210779010915444\n",
      "  (17899, 70081)\t0.020210779010915444\n",
      "  (17899, 58832)\t10.792555991828847\n",
      "  (17899, 48586)\t2.2132380307550483\n",
      "  (17899, 45283)\t0.1254948371142889\n",
      "  (17899, 40500)\t0.2997932219952457\n",
      "  (17899, 39251)\t0.9643710559929419\n",
      "  (17899, 35404)\t0.25749741314035207\n",
      "  (17899, 35305)\t0.17458399390484305\n",
      "  (17899, 17182)\t2.423485925790184\n",
      "  (17899, 16296)\t0.13248255817899937\n",
      "  (17899, 8110)\t0.02746197453391564\n",
      "  (17899, 4184)\t0.0008653051288411002\n"
     ]
    }
   ],
   "source": [
    "print(len(train_news))\n",
    "print(len(test_news))\n",
    "print(len(train_label))\n",
    "print(len(test_label))\n",
    "print(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2419, 74109)\n",
      "17900\n",
      "(17900, 74109)\n"
     ]
    }
   ],
   "source": [
    "#transform to vector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer=DictVectorizer()\n",
    "transformer=TfidfTransformer(smooth_idf=False,norm=None)\n",
    "train_matrix=vectorizer.fit_transform(train_news)\n",
    "#use TF_IDF\n",
    "train_matrix=transformer.fit_transform(train_matrix)\n",
    "\n",
    "#transform test\n",
    "test_matrix=vectorizer.transform(test_news)\n",
    "test_matrix=transformer.transform(test_matrix)\n",
    "print(test_matrix.shape)\n",
    "print(len(train_label))\n",
    "print(train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do prediction and evaluation matrix for later works\n",
    "def prediction(model):\n",
    "    #best=model.fit(train_matrix,train_label)\n",
    "    pre=model.predict(test_matrix)\n",
    "    rmse = np.sqrt(np.mean((test_label - pre)**2))\n",
    "    psr=stats.pearsonr(np.array(pre),np.array(test_label))\n",
    "    print(\"The person correlation coefficient is:\")\n",
    "    print(psr)\n",
    "    print(\"The result of RMSE in the whole test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:100])\n",
    "    rmse = np.sqrt(np.mean((test_label[:100] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 10% test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:200])\n",
    "    rmse = np.sqrt(np.mean((test_label[:200] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 20% test data is:\")\n",
    "    print(rmse)\n",
    "    pre=model.predict(test_matrix[:300])\n",
    "    rmse = np.sqrt(np.mean((test_label[:300] - pre)**2))    \n",
    "    print(\"The result of RMSE in the BEST 30% test data is:\")\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'alpha': 0.01} with R2——score of -0.00032\n",
      "The person correlation coefficient is:\n",
      "(-0.020239753226676954, 0.3197139532215622)\n",
      "The result of RMSE in the whole test data is:\n",
      "0.5990002561616723\n",
      "The result of RMSE in the BEST 10% test data is:\n",
      "0.5863093134034103\n",
      "The result of RMSE in the BEST 20% test data is:\n",
      "0.5821869173441703\n",
      "The result of RMSE in the BEST 30% test data is:\n",
      "0.5790585601019096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit,GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import make_scorer,mean_squared_error,r2_score\n",
    "\n",
    "#use MSE as scorer\n",
    "#scorer=make_scorer(mean_squared_error)\n",
    "scorer=make_scorer(r2_score)\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.1, random_state=0)\n",
    "\n",
    "#LASSO Method (alpha from 0.1 to 100)\n",
    "a=np.logspace(-2,4,10)\n",
    "lasso=linear_model.Lasso(fit_intercept=True)\n",
    "grid=GridSearchCV(lasso,param_grid={'alpha':a},cv=cv,scoring=scorer)\n",
    "grid.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2——score of {0.best_score_:.3g}\".format(grid))\n",
    "best=grid.best_estimator_ \n",
    "prediction(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5941466132512262\n"
     ]
    }
   ],
   "source": [
    "test_eval_matrix=vectorizer.transform(test_eval_news)\n",
    "test_eval_matrix=transformer.transform(test_eval_matrix)\n",
    "\n",
    "pre=grid.predict(test_eval_matrix)\n",
    "rmse = np.sqrt(np.mean((test_eval_label - pre)**2))\n",
    "print(rmse)\n",
    "import pandas as pd\n",
    "id=test_eval.id\n",
    "dataframe = pd.DataFrame({'id':id,'pred':pre})\n",
    "dataframe.to_csv(\"task-1-output.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'alpha': 16681.005372000593} with R2-score of 0.0921\n",
      "The person correlation coefficient is:\n",
      "(0.334558900664955, 6.669315156841847e-16)\n",
      "The result of RMSE in the whole test data is:\n",
      "0.5332356662450543\n",
      "The result of RMSE in the BEST 10% test data is:\n",
      "0.8166910431997259\n",
      "The result of RMSE in the BEST 20% test data is:\n",
      "0.6333492806158451\n",
      "The result of RMSE in the BEST 30% test data is:\n",
      "0.5262552755566311\n"
     ]
    }
   ],
   "source": [
    "#ridge method \n",
    "ridge=linear_model.Ridge(solver='sparse_cg')\n",
    "a=np.logspace(-2,5,10)\n",
    "grid2=GridSearchCV(ridge,param_grid={'alpha':a},cv=cv,scoring=scorer)\n",
    "grid2.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid2))\n",
    "prediction(grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#elasticnet method\n",
    "#alpha and ratio for L1\n",
    "a=np.linspace(0.01,5,10)\n",
    "b=np.linspace(0,1,5)\n",
    "elastic=linear_model.ElasticNet()\n",
    "\n",
    "grid3=GridSearchCV(elastic,param_grid={'alpha':a,'l1_ratio':b},cv=cv,scoring=make_scorer(mean_squared_error))\n",
    "grid3.fit(train_matrix,train_label)\n",
    "\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid3))\n",
    "prediction(grid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from sklearn.svm import SVR\n",
    "c_range=np.logspace(-2,5,10)\n",
    "gamma=np.logspace(-5,1,10)\n",
    "degree=[0,1,2,3,4]\n",
    "svr=SVR(kernel='poly')\n",
    "\n",
    "grid4=GridSearchCV(svr,param_grid={'epsilon':epsilon,'C':c_range,'degree':degree},cv=cv,scoring=scorer)\n",
    "grid4.fit(train_matrix,train_label)\n",
    "print(\"The best parameters are {0.best_params_} with R2-score of {0.best_score_:.3g}\".format(grid4))\n",
    "prediction(grid4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
