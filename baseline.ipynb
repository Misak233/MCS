{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train_data = \"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/train.csv\"\n",
    "test_data=\"/Users/zxj/Desktop/study/semester3/MCS/humor/data/task-1/dev.csv\"\n",
    "train=pd.read_csv(train_data)\n",
    "train_label=train.meanGrade\n",
    "test_label=train_label[9100:]\n",
    "train_label=train_label[:9100]\n",
    "train_news=train.original\n",
    "funny_word=train.edit\n",
    "train_id=train.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is ‘ hunting down its citizens who joined <Isis/> ’ without trial in Iraq\n"
     ]
    }
   ],
   "source": [
    "def find_tag(news):\n",
    "    p = re.compile(r'[<](.*?)/[>]', re.S)\n",
    "    return re.findall(p, news)\n",
    "print(train_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do preprocess\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "tt=nltk.tokenize.regexp.WordPunctTokenizer()\n",
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def preprocess_news(sentence):\n",
    "    final=[]\n",
    "    num=0\n",
    "    for event in sentence:\n",
    "        BOW={}\n",
    "        ori=event\n",
    "        event=removePunctuation(event)\n",
    "        event=tt.tokenize(event)\n",
    "        for words in event:\n",
    "            words=lemmatizer.lemmatize(words)\n",
    "            if words not in stopwords:\n",
    "                BOW[words.lower()]=BOW.get(words,0)+1\n",
    "        BOW[funny_word[num].lower()]=BOW.get(funny_word[num],0)+10\n",
    "        final.append(BOW)\n",
    "        num+=1\n",
    "    return final\n",
    "\n",
    "punctuation = '!,;:?\"\\'.\\'/<>'\n",
    "def removePunctuation(text):\n",
    "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
    "    return text.strip()\n",
    "\n",
    "train_news=preprocess_news(train_news)\n",
    "test_news=train_news[9100:]\n",
    "train_news=train_news[:9100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100\n",
      "552\n",
      "9100\n",
      "552\n",
      "{'france': 1, '‘': 1, 'hunting': 1, 'citizen': 1, 'joined': 1, 'isis': 1, '’': 1, 'without': 1, 'trial': 1, 'iraq': 1, 'twins': 10}\n"
     ]
    }
   ],
   "source": [
    "print(len(train_news))\n",
    "print(len(test_news))\n",
    "print(len(train_label))\n",
    "print(len(test_label))\n",
    "print(train_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552, 10191)\n",
      "(1, 10191)\n"
     ]
    }
   ],
   "source": [
    "#transform to vector\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer=DictVectorizer()\n",
    "transformer=TfidfTransformer(smooth_idf=False,norm=None)\n",
    "train_matrix=vectorizer.fit_transform(train_news)\n",
    "train_matrix=transformer.fit_transform(train_matrix)\n",
    "test_matrix=vectorizer.transform(test_news)\n",
    "test_matrix=transformer.transform(test_matrix)\n",
    "print(test_matrix.shape)\n",
    "print(train_matrix[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression(fit_intercept=True, normalize=False, copy_X=False, n_jobs=None)\n",
    "model.fit(train_matrix,train_label)\n",
    "pre1=model.predict(test_matrix)\n",
    "pre=[]\n",
    "for i in pre1:\n",
    "    if i<0:\n",
    "        i=0\n",
    "    elif i>1:\n",
    "        i=1\n",
    "    pre.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model2=svm.SVR(kernel='rbf')\n",
    "model2.fit(train_matrix,train_label)\n",
    "pre2=model2.predict(test_matrix)\n",
    "pre=[]\n",
    "for i in pre2:\n",
    "    if i<0:\n",
    "        i=0\n",
    "    elif i>1:\n",
    "        i=1\n",
    "    pre.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5805943855462934\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean((test_label - pre)**2))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,ShuffleSplit,cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "clf=svm.SVR(kernel='rbf')\n",
    "score1=cross_val_score(clf, train_matrix, train_label, cv=cv,scoring='r2')\n",
    "print(score1.mean())\n",
    "clf2=model=LinearRegression(fit_intercept=True, normalize=False, copy_X=False, n_jobs=None)\n",
    "score2=cross_val_score(clf2, train_matrix, train_label, cv=cv,scoring='r2')\n",
    "score2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
